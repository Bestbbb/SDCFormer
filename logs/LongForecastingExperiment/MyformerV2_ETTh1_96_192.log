Args in experiment:
Namespace(activation='gelu', anomaly_ratio=0.25, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='ETTh1.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, dropout=0.1, e_layers=2, embed='timeF', enc_in=7, factor=3, features='M', freq='h', gpu=0, head_dropout=0.0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='MSE', lradj='type1', mask_rate=0.25, model='MyformerV2', model_id='96_192', moving_avg=25, multi_moving_avg=[13, 17, 21, 25, 29, 31], n_heads=4, num_kernels=6, num_workers=10, output_attention=False, p_hidden_dims=[128, 128], p_hidden_layers=2, patch_len=16, patience=3, pred_len=192, root_path='./dataset/ETT-small/', seasonal_patterns='Monthly', seq_len=96, show_model=False, stride=8, target='OT', task_name='long_term_forecast', top_k=5, train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_96_192_MyformerV2_custom_ftM_sl96_ll48_pl192_dm512_nh4_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11907
val 1551
test 3293
Epoch: 1 cost time: 80.52693462371826
Epoch: 1, Steps: 93 | Train Loss: 0.5370271 Vali Loss: 0.3919207 Test Loss: 0.5429456
Validation loss decreased (inf --> 0.391921).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 79.2938883304596
Epoch: 2, Steps: 93 | Train Loss: 0.5120435 Vali Loss: 0.3920690 Test Loss: 0.5552882
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
Epoch: 3 cost time: 79.56468439102173
Epoch: 3, Steps: 93 | Train Loss: 0.5042358 Vali Loss: 0.3844185 Test Loss: 0.5395058
Validation loss decreased (0.391921 --> 0.384418).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 79.45815372467041
Epoch: 4, Steps: 93 | Train Loss: 0.5001940 Vali Loss: 0.3766235 Test Loss: 0.5326056
Validation loss decreased (0.384418 --> 0.376623).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 79.63070678710938
Epoch: 5, Steps: 93 | Train Loss: 0.4982634 Vali Loss: 0.3737344 Test Loss: 0.5224677
Validation loss decreased (0.376623 --> 0.373734).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 79.56846761703491
Epoch: 6, Steps: 93 | Train Loss: 0.4971850 Vali Loss: 0.3768115 Test Loss: 0.5182778
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 79.52313327789307
Epoch: 7, Steps: 93 | Train Loss: 0.4969065 Vali Loss: 0.3737868 Test Loss: 0.5200323
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 79.42419362068176
Epoch: 8, Steps: 93 | Train Loss: 0.4962481 Vali Loss: 0.3723544 Test Loss: 0.5207037
Validation loss decreased (0.373734 --> 0.372354).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 79.49785995483398
Epoch: 9, Steps: 93 | Train Loss: 0.4964551 Vali Loss: 0.3737531 Test Loss: 0.5198006
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 79.41939926147461
Epoch: 10, Steps: 93 | Train Loss: 0.4963646 Vali Loss: 0.3744136 Test Loss: 0.5183219
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_96_192_MyformerV2_custom_ftM_sl96_ll48_pl192_dm512_nh4_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3293
test shape: (3293, 1, 192, 7) (3293, 1, 192, 7)
test shape: (3293, 192, 7) (3293, 192, 7)
mse:0.5207037925720215, mae:0.5067877173423767
