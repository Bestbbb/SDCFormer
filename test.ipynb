{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from torch import Tensor\n",
    "from tqdm.notebook import tqdm  # Progress bar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((3,))\n",
    "print(x.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([0., 1., 2.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32, requires_grad=True)  # Only float tensors can have gradients\n",
    "print(\"X\", x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = x + 2\n",
    "b = a**2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(\"Y\", y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "y.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.3333, 2.0000, 2.6667])"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time: 0.61136s\n",
      "GPU time: 0.19415s\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5000, 5000)\n",
    "\n",
    "# CPU version\n",
    "start_time = time.time()\n",
    "_ = torch.matmul(x, x)\n",
    "end_time = time.time()\n",
    "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
    "# GPU version\n",
    "if torch.cuda.is_available():\n",
    "    x = x.to(device)\n",
    "    # CUDA is asynchronous, so we need to use different timing functions\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    _ = torch.matmul(x, x)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
    "    print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize the modules we need to build the network\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.act_fn = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.linear1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassifier(\n",
      "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (act_fn): Tanh()\n",
      "  (linear2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "Parameter linear1.weight, shape torch.Size([4, 2])\n",
      "Parameter linear1.bias, shape torch.Size([4])\n",
      "Parameter linear2.weight, shape torch.Size([1, 4])\n",
      "Parameter linear2.bias, shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "# Printing a module shows all its submodules\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name}, shape {param.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class XORDataset(data.Dataset):\n",
    "    def __init__(self, size, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_continuous_xor()\n",
    "\n",
    "    def generate_continuous_xor(self):\n",
    "        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1\n",
    "        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.\n",
    "        # If x=y, the label is 0.\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([-0.1551,  0.9780]), tensor(1))"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = XORDataset(size=200)\n",
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inputs torch.Size([8, 2]) \n",
      " tensor([[ 0.0652,  1.0126],\n",
      "        [-0.0993,  1.0482],\n",
      "        [ 1.0389,  0.1050],\n",
      "        [ 0.9692,  0.0072],\n",
      "        [ 0.9528,  0.1234],\n",
      "        [ 0.9717,  0.9721],\n",
      "        [ 1.0728,  1.0110],\n",
      "        [ 1.1344,  0.1440]])\n",
      "Data labels torch.Size([8]) \n",
      " tensor([1, 1, 1, 1, 1, 0, 0, 1])\n",
      "x tensor([[ 0.9236,  1.2389],\n",
      "        [-0.1895,  0.0415],\n",
      "        [ 1.0006, -0.0328],\n",
      "        [ 1.1356,  0.9897],\n",
      "        [ 0.0238,  0.1245],\n",
      "        [ 0.0253,  0.9259],\n",
      "        [ 1.0245, -0.0026],\n",
      "        [ 0.8484,  0.0956]])\n",
      "y tensor([0, 0, 1, 0, 0, 1, 1, 1])\n",
      "x tensor([[ 0.0483,  0.9763],\n",
      "        [ 0.0181,  0.0113],\n",
      "        [-0.1895,  0.0491],\n",
      "        [-0.1033, -0.0035],\n",
      "        [ 1.0602, -0.0724],\n",
      "        [ 0.9495, -0.0157],\n",
      "        [ 0.1236,  0.1485],\n",
      "        [-0.0378,  1.0500]])\n",
      "y tensor([1, 0, 0, 0, 1, 1, 0, 1])\n",
      "x tensor([[ 1.1615,  0.0324],\n",
      "        [ 0.8822,  0.7730],\n",
      "        [ 0.9787, -0.0072],\n",
      "        [ 0.0976,  0.8198],\n",
      "        [ 0.8450, -0.1084],\n",
      "        [ 1.0728,  1.0110],\n",
      "        [-0.0853, -0.0514],\n",
      "        [ 1.1135,  0.1228]])\n",
      "y tensor([1, 0, 1, 1, 1, 0, 0, 1])\n",
      "x tensor([[ 9.4724e-01,  1.1881e+00],\n",
      "        [-1.7066e-02,  5.2070e-02],\n",
      "        [ 8.8698e-01,  7.3760e-02],\n",
      "        [ 2.6423e-02, -3.1869e-02],\n",
      "        [-1.3577e-04,  1.0380e+00],\n",
      "        [ 9.7175e-01,  9.7215e-01],\n",
      "        [ 1.1346e+00, -2.3331e-03],\n",
      "        [-1.3276e-01,  9.6761e-01]])\n",
      "y tensor([0, 0, 1, 0, 1, 0, 1, 1])\n",
      "x tensor([[ 1.0531,  1.1153],\n",
      "        [ 1.0338,  0.9521],\n",
      "        [ 1.1358,  0.8156],\n",
      "        [ 1.0717, -0.1914],\n",
      "        [ 0.1273,  1.1477],\n",
      "        [ 1.0955,  0.7728],\n",
      "        [ 0.9739,  0.8980],\n",
      "        [ 0.2706,  0.9927]])\n",
      "y tensor([0, 0, 0, 1, 1, 0, 0, 1])\n",
      "x tensor([[ 0.0111,  1.1941],\n",
      "        [ 0.0957, -0.0276],\n",
      "        [-0.1498,  0.0798],\n",
      "        [-0.1071,  0.9719],\n",
      "        [ 1.0113,  1.0343],\n",
      "        [-0.0392,  0.8611],\n",
      "        [ 1.0181,  0.2056],\n",
      "        [-0.1782,  0.9747]])\n",
      "y tensor([1, 0, 0, 1, 0, 1, 1, 1])\n",
      "x tensor([[ 0.7597,  1.0986],\n",
      "        [ 0.0985,  0.0424],\n",
      "        [ 0.0211,  0.9829],\n",
      "        [ 0.9768,  0.0396],\n",
      "        [ 0.1759, -0.0792],\n",
      "        [ 0.9715,  1.0497],\n",
      "        [ 1.0373,  0.0439],\n",
      "        [-0.1852,  0.9849]])\n",
      "y tensor([0, 0, 1, 1, 0, 0, 1, 1])\n",
      "x tensor([[ 0.9615,  0.9262],\n",
      "        [ 0.9715, -0.0188],\n",
      "        [ 1.1344,  0.1440],\n",
      "        [-0.1438,  0.0536],\n",
      "        [-0.0192, -0.2430],\n",
      "        [ 0.0313,  0.9780],\n",
      "        [ 0.9877,  1.0747],\n",
      "        [ 0.9942, -0.0456]])\n",
      "y tensor([0, 1, 1, 0, 0, 1, 0, 1])\n",
      "x tensor([[ 0.0797,  0.9888],\n",
      "        [ 1.0544, -0.0105],\n",
      "        [ 0.9277,  0.0978],\n",
      "        [-0.0890,  0.8608],\n",
      "        [-0.0098,  0.7925],\n",
      "        [ 0.9288,  0.9939],\n",
      "        [-0.0533,  0.9612],\n",
      "        [-0.1551,  0.9780]])\n",
      "y tensor([1, 1, 1, 1, 1, 0, 1, 1])\n",
      "x tensor([[ 0.9346, -0.1000],\n",
      "        [ 1.0417,  0.9265],\n",
      "        [-0.0356,  0.0867],\n",
      "        [ 1.1136,  0.9546],\n",
      "        [ 0.0382,  0.9786],\n",
      "        [ 1.1297,  1.1860],\n",
      "        [ 1.0990, -0.1169],\n",
      "        [-0.0494, -0.0687]])\n",
      "y tensor([1, 0, 0, 0, 1, 0, 1, 0])\n",
      "x tensor([[ 0.7967,  0.2268],\n",
      "        [ 0.9287,  0.0536],\n",
      "        [-0.0167,  0.0457],\n",
      "        [ 0.9771,  1.0395],\n",
      "        [ 1.0385,  0.9311],\n",
      "        [ 1.0150,  0.9689],\n",
      "        [ 1.0454,  1.0747],\n",
      "        [ 0.2202, -0.0534]])\n",
      "y tensor([1, 1, 0, 0, 0, 0, 0, 0])\n",
      "x tensor([[-0.0543,  1.0935],\n",
      "        [-0.0551,  1.0486],\n",
      "        [ 0.1587,  0.1399],\n",
      "        [ 0.9061,  0.0552],\n",
      "        [ 0.1248,  0.8269],\n",
      "        [ 0.1522, -0.1591],\n",
      "        [ 0.9852, -0.0393],\n",
      "        [-0.2017,  0.9749]])\n",
      "y tensor([1, 1, 0, 1, 1, 0, 1, 1])\n",
      "x tensor([[ 1.1162, -0.0718],\n",
      "        [-0.0460, -0.0798],\n",
      "        [ 0.1076, -0.0328],\n",
      "        [ 0.0453,  0.0408],\n",
      "        [ 1.1164,  0.8534],\n",
      "        [ 1.1063,  1.0690],\n",
      "        [ 1.0650,  0.9507],\n",
      "        [ 0.0287, -0.1492]])\n",
      "y tensor([1, 0, 0, 0, 0, 0, 0, 0])\n",
      "x tensor([[ 0.0407,  1.0698],\n",
      "        [ 0.1257,  1.0030],\n",
      "        [ 0.0835,  0.0036],\n",
      "        [ 0.9595, -0.0991],\n",
      "        [-0.0703,  0.9643],\n",
      "        [ 1.0211,  0.8252],\n",
      "        [ 0.0880,  1.0448],\n",
      "        [ 1.0498,  0.9981]])\n",
      "y tensor([1, 1, 0, 1, 1, 0, 1, 0])\n",
      "x tensor([[-0.0636,  0.9167],\n",
      "        [ 1.0230,  1.0787],\n",
      "        [ 1.1821, -0.0943],\n",
      "        [ 0.1317, -0.0623],\n",
      "        [ 1.1013,  1.1492],\n",
      "        [ 0.9667,  0.0190],\n",
      "        [ 0.0058, -0.1076],\n",
      "        [-0.2801, -0.0241]])\n",
      "y tensor([1, 0, 1, 0, 0, 1, 0, 0])\n",
      "x tensor([[-0.0057,  0.8682],\n",
      "        [ 1.1961,  0.9384],\n",
      "        [-0.0889,  0.9878],\n",
      "        [-0.0993,  1.0482],\n",
      "        [ 1.0428,  1.0384],\n",
      "        [ 0.8782, -0.0944],\n",
      "        [ 1.0169,  1.1633],\n",
      "        [ 0.1893,  1.0949]])\n",
      "y tensor([1, 0, 1, 1, 0, 1, 0, 1])\n",
      "x tensor([[ 9.4351e-01,  8.5333e-01],\n",
      "        [ 9.2579e-02,  9.2784e-01],\n",
      "        [ 2.0569e-02,  1.0667e+00],\n",
      "        [ 3.8939e-02, -1.3861e-01],\n",
      "        [-1.1807e-01, -5.0060e-02],\n",
      "        [-7.6168e-02,  1.0175e+00],\n",
      "        [ 1.0833e+00, -1.5113e-01],\n",
      "        [ 1.0628e-01, -4.4506e-04]])\n",
      "y tensor([0, 1, 1, 0, 0, 1, 1, 0])\n",
      "x tensor([[ 0.9832,  0.0462],\n",
      "        [-0.0445,  1.1621],\n",
      "        [ 0.9180,  1.0317],\n",
      "        [-0.0148,  0.0103],\n",
      "        [ 0.0134,  0.9198],\n",
      "        [ 0.9692,  0.0072],\n",
      "        [ 0.8955,  1.1699],\n",
      "        [ 1.0489, -0.1283]])\n",
      "y tensor([1, 1, 0, 0, 1, 1, 0, 1])\n",
      "x tensor([[ 0.9229, -0.0574],\n",
      "        [-0.0237, -0.0595],\n",
      "        [ 0.0099, -0.0340],\n",
      "        [ 1.1257,  0.9543],\n",
      "        [ 0.0187,  0.8899],\n",
      "        [ 0.2403,  0.9906],\n",
      "        [ 0.9607,  0.1388],\n",
      "        [ 0.9528,  0.1234]])\n",
      "y tensor([1, 0, 0, 0, 1, 1, 1, 1])\n",
      "x tensor([[ 0.8079,  0.0317],\n",
      "        [ 1.0881,  1.1791],\n",
      "        [ 0.0729,  0.8244],\n",
      "        [ 0.8410,  1.1353],\n",
      "        [ 1.0076,  1.0567],\n",
      "        [ 0.9400,  0.8880],\n",
      "        [ 1.0004,  1.0789],\n",
      "        [ 1.1825, -0.0483]])\n",
      "y tensor([1, 0, 1, 0, 0, 0, 0, 1])\n",
      "x tensor([[-0.0688,  0.0371],\n",
      "        [ 0.0522, -0.0969],\n",
      "        [ 0.0652,  1.0126],\n",
      "        [ 0.8291,  0.0303],\n",
      "        [ 0.9080, -0.1102],\n",
      "        [ 0.8639, -0.0258],\n",
      "        [-0.0623,  0.0734],\n",
      "        [ 0.8339,  0.0472]])\n",
      "y tensor([0, 0, 1, 1, 1, 1, 0, 1])\n",
      "x tensor([[ 0.0996,  0.0249],\n",
      "        [ 0.0046, -0.1144],\n",
      "        [ 0.2042,  1.0317],\n",
      "        [ 0.1724, -0.0142],\n",
      "        [-0.0217, -0.1180],\n",
      "        [ 1.0270, -0.1197],\n",
      "        [ 0.9400,  0.8676],\n",
      "        [ 1.0389,  0.1050]])\n",
      "y tensor([0, 0, 1, 0, 0, 1, 0, 1])\n",
      "x tensor([[ 0.1374,  1.0702],\n",
      "        [ 0.0452, -0.0288],\n",
      "        [ 1.0797,  0.0872],\n",
      "        [-0.1262,  1.1337],\n",
      "        [ 0.0487, -0.1395],\n",
      "        [ 1.0557,  0.9647],\n",
      "        [ 0.0759, -0.0578],\n",
      "        [ 0.0226,  0.9619]])\n",
      "y tensor([1, 0, 1, 1, 0, 0, 0, 1])\n",
      "x tensor([[ 1.1102,  0.7645],\n",
      "        [ 1.0186,  0.9369],\n",
      "        [ 1.1276,  1.0467],\n",
      "        [ 0.9273,  0.7652],\n",
      "        [-0.0620,  1.0288],\n",
      "        [ 0.1013,  0.0256],\n",
      "        [ 0.8157, -0.0107],\n",
      "        [ 0.0034, -0.0361]])\n",
      "y tensor([0, 0, 0, 0, 1, 0, 1, 0])\n",
      "x tensor([[ 0.9381,  1.0959],\n",
      "        [ 0.0701,  0.0687],\n",
      "        [ 1.0819,  0.9470],\n",
      "        [ 0.0601,  1.1108],\n",
      "        [ 0.9411,  1.0492],\n",
      "        [-0.2194, -0.1724],\n",
      "        [-0.0421,  0.1104],\n",
      "        [-0.0274, -0.0692]])\n",
      "y tensor([0, 0, 0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size=8\n",
    "                              , shuffle=True)\n",
    "data_inputs, data_labels = next(iter(data_loader))\n",
    "\n",
    "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the\n",
    "# dimensions of the data point returned from the dataset class\n",
    "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
    "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)\n",
    "for x,y in data_loader:\n",
    "    print(\"x\",x)\n",
    "    print(\"y\",y)\n",
    "# for i,(batch_x,batch_y) in enumerate(data_loader):\n",
    "#     print(i,batch_x)\n",
    "#     print(batch_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "loss_module = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleClassifier(\n  (linear1): Linear(in_features=2, out_features=4, bias=True)\n  (act_fn): Tanh()\n  (linear2): Linear(in_features=4, out_features=1, bias=True)\n)"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = XORDataset(size=1000)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fd0f8e2ec4447edad90f98c196e14da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs,data_labels in data_loader:\n",
    "            # Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "\n",
    "            # Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            # Step 3: Calculate the loss\n",
    "            loss = loss_module(preds,data_labels.float())\n",
    "            # Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero.\n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad()\n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 5: Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "train_model(model, optimizer, train_data_loader, loss_module)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear1.weight', tensor([[ 2.5314, -2.3760],\n",
      "        [-0.4756, -0.5388],\n",
      "        [-1.2652, -0.3048],\n",
      "        [-1.0653,  1.7114]], device='cuda:0')), ('linear1.bias', tensor([ 1.3886, -0.7650,  0.2168,  0.3253], device='cuda:0')), ('linear2.weight', tensor([[-2.6771, -0.7409, -1.0515, -2.0297]], device='cuda:0')), ('linear2.bias', tensor([0.9799], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "print(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "torch.save(state_dict, \"our_model.tar\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model\n",
      " OrderedDict([('linear1.weight', tensor([[ 2.5314, -2.3760],\n",
      "        [-0.4756, -0.5388],\n",
      "        [-1.2652, -0.3048],\n",
      "        [-1.0653,  1.7114]], device='cuda:0')), ('linear1.bias', tensor([ 1.3886, -0.7650,  0.2168,  0.3253], device='cuda:0')), ('linear2.weight', tensor([[-2.6771, -0.7409, -1.0515, -2.0297]], device='cuda:0')), ('linear2.bias', tensor([0.9799], device='cuda:0'))])\n",
      "\n",
      "Loaded model\n",
      " OrderedDict([('linear1.weight', tensor([[ 2.5314, -2.3760],\n",
      "        [-0.4756, -0.5388],\n",
      "        [-1.2652, -0.3048],\n",
      "        [-1.0653,  1.7114]])), ('linear1.bias', tensor([ 1.3886, -0.7650,  0.2168,  0.3253])), ('linear2.weight', tensor([[-2.6771, -0.7409, -1.0515, -2.0297]])), ('linear2.bias', tensor([0.9799]))])\n"
     ]
    }
   ],
   "source": [
    "# Load state dict from the disk (make sure it is the same name as above)\n",
    "state_dict = torch.load(\"our_model.tar\")\n",
    "\n",
    "# Create a new model and load the state\n",
    "new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)\n",
    "new_model.load_state_dict(state_dict)\n",
    "\n",
    "# Verify that the parameters are the same\n",
    "print(\"Original model\\n\", model.state_dict())\n",
    "print(\"\\nLoaded model\\n\", new_model.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "test_dataset = XORDataset(size=500)\n",
    "test_data_loader = data.DataLoader(test_dataset,batch_size=128,shuffle=False,drop_last=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "def eval_model(model,data_loader):\n",
    "    model.eval()\n",
    "    true_preds, num_preds = 0.0,0.0\n",
    "    with torch.no_grad():\n",
    "        for data_inputs,data_labels in data_loader:\n",
    "            data_inputs,data_labels = data_inputs.to(device),data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            preds = torch.sigmoid(preds)\n",
    "            pred_labels = (preds >= 0.5).long()  # Binarize predictions to 0 and 1\n",
    "\n",
    "            true_preds+=(pred_labels==data_labels).sum()\n",
    "            num_preds+=data_labels.shape[0]\n",
    "\n",
    "    acc = true_preds/num_preds\n",
    "    print(f\"Accuracy of the model:{100.0*acc:4.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:99.80%\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, test_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " tensor([[ 0.3367,  0.1288],\n",
      "        [ 0.2345,  0.2303],\n",
      "        [-1.1229, -0.1863]])\n",
      "K\n",
      " tensor([[ 2.2082, -0.6380],\n",
      "        [ 0.4617,  0.2674],\n",
      "        [ 0.5349,  0.8094]])\n",
      "V\n",
      " tensor([[ 1.1103, -1.6898],\n",
      "        [-0.9890,  0.9580],\n",
      "        [ 1.3221,  0.8172]])\n",
      "Values\n",
      " tensor([[ 0.5698, -0.1520],\n",
      "        [ 0.5379, -0.0265],\n",
      "        [ 0.2246,  0.5556]])\n",
      "Attention\n",
      " tensor([[0.4028, 0.2886, 0.3086],\n",
      "        [0.3538, 0.3069, 0.3393],\n",
      "        [0.1303, 0.4630, 0.4067]])\n"
     ]
    }
   ],
   "source": [
    "seq_len, d_k = 3, 2\n",
    "pl.seed_everything(42)\n",
    "q = torch.randn(seq_len, d_k)\n",
    "k = torch.randn(seq_len, d_k)\n",
    "v = torch.randn(seq_len, d_k)\n",
    "values, attention = scaled_dot_product(q, k, v)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"Values\\n\", values)\n",
    "print(\"Attention\\n\", attention)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}